"""
Object Detection on Panorama pictures and videos
Usage:
    $ python detection.py --img <input_file> --output <output_file>
    $ python detection.py --video <input_file> --output <output_file>

    input_file (str):  the input panorama image or video
    output_file (str): the output panorama image or video with bounding boxes
"""

import argparse
import queue
import sys
import cv2
import imageio
import json
import numpy as np
from yolov8_model_run import detect
from stereo import panorama_to_stereo_multiprojections, stereo_bounding_boxes_to_panorama
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from queue import Queue

def video_detection(input_video_path, stereographic_image_size, FOV, output_image_file_path, output_json_file_path, thread_count, seconds_process=-1):
    '''
    Function:
        Take in a set of equirectangular panoramas (360-degree video) and apply object detection.
        Split each panorama frame into 4 images based on stereographic projection.
        Run Yolov8 model finetuned with coco128 on each image to generate bounding boxes.
        Draw bounding boxes back on panoramas.

        Based on "Object Detection in Equirectangular Panorama".
    '''

    try:
        video_reader = cv2.VideoCapture(input_video_path)
    except:
        print("Failed to read input video path.")

    # Ensure that video opened successfully
    if not video_reader.isOpened():
        print("Error: Could not open video.")
        exit()

    annotated_panoramas = {}
    panorama_detections = {}

    fps = video_reader.get(cv2.CAP_PROP_FPS)
    total_num_frames = video_reader.get(cv2.CAP_PROP_FRAME_COUNT)
    frames_specified = seconds_process * int(fps)
    if frames_specified > 0:
        total_num_frames = frames_specified
    print("Frame Rate: ", fps)
    print("Total number of frames: ", total_num_frames)

    def process_frame(frame_count, pano_array, stereographic_image_size, FOV):
        # Get frames along with (yaw, pitch) rotation value for the 4 stereographic projections for input panorama
        frames = panorama_to_stereo_multiprojections(pano_array, stereographic_image_size, FOV)

        # Get bounding boxes for each frame
        frames_detections_with_meta = []
        for frame in frames:
            detections = detect(frame['image'], confidence_threshold=0.45)
            cleaned_detections = []
            for detection in detections:
                box = detection['box']
                if not (box[0] < 5 or box[1] < 5 or box[0] + box[2] > frame['image'].shape[0] - 5 or box[1] + box[3] > frame['image'].shape[1] - 5):
                    cleaned_detections.append(detection)
            detections_with_meta = (cleaned_detections, frame['yaw'], frame['pitch'])
            frames_detections_with_meta.append(detections_with_meta)

        frames_detections_with_meta_np = np.array(frames_detections_with_meta, dtype=np.dtype([('image_detections', np.ndarray), ('yaw', int), ('pitch', int)]))
        output_panorama_np, pano_detections = stereo_bounding_boxes_to_panorama(frames_detections_with_meta_np, pano_array, stereographic_image_size, FOV)
        return (output_panorama_np, pano_detections, frame_count, 0)

    if thread_count == 1:
        print("Processing frames")
        for frame_count in tqdm(range(int(total_num_frames))):
            ret, pano_array = video_reader.read()
            if not ret:
                print("Finished reading all frames before expected")
                break
            pano_array = cv2.resize(pano_array, (1920, 960))  # Downscale for memory safety
            output_panorama_np, pano_detections, fr_index, code = process_frame(frame_count, pano_array, stereographic_image_size, FOV)
            if code != 0:
                print(f"Task failed, code: {code}")
            else:
                annotated_panoramas[fr_index] = output_panorama_np
                panorama_detections[fr_index] = pano_detections

    elif thread_count > 1:
        print("Processing frames")
        with ThreadPoolExecutor(max_workers=thread_count) as executor:
            futures = queue.Queue()
            for frame_count in tqdm(range(int(total_num_frames))):
                ret, pano_array = video_reader.read()
                if not ret:
                    print("Finished reading all frames before expected")
                    break
                pano_array = cv2.resize(pano_array, (1920, 960))  # Downscale for memory safety
                future = executor.submit(process_frame, frame_count, pano_array, stereographic_image_size, FOV)
                futures.put(future)
                while futures.qsize() > thread_count * 2:
                    future = futures.get()
                    output_panorama_np, pano_detections, fr_index, code = future.result()
                    if code != 0:
                        print(f"Task failed, code: {code}")
                    else:
                        annotated_panoramas[fr_index] = output_panorama_np
                        panorama_detections[fr_index] = pano_detections

            while not futures.empty():
                future = futures.get()
                output_panorama_np, pano_detections, fr_index, code = future.result()
                if code != 0:
                    print(f"Task failed, code: {code}")
                else:
                    annotated_panoramas[fr_index] = output_panorama_np
                    panorama_detections[fr_index] = pano_detections

    video_reader.release()

    json_pano_detections = {}
    for fr_index in panorama_detections:
        json_pano_detection = []
        for detection_index in range(panorama_detections[fr_index].shape[0]):
            for detection in range(len(panorama_detections[fr_index][detection_index])):
                json_pano_detection.append(panorama_detections[fr_index][detection_index][detection])
        json_pano_detections[fr_index] = json_pano_detection

    if output_json_file_path:
        json_object = json.dumps(json_pano_detections, indent=4)
        with open(output_json_file_path, "w") as outfile:
            outfile.write(json_object)

    if output_image_file_path:
        video_writer = imageio.get_writer(output_image_file_path, fps=int(fps))
        print("Writing frames")
        for i in tqdm(range(int(total_num_frames))):
            output_image = annotated_panoramas[i]
            rgb_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)
            video_writer.append_data(rgb_image)
        video_writer.close()
        print("The annotated 360 video file has been written successfully.")

def image_detection(input_panorama_path, stereographic_image_size, FOV, output_image_file_path, output_json_file_path):
    try:
        pano_array = cv2.imread(input_panorama_path)
    except:
        print("Failed to read input panorama path.")

    if pano_array is None:
        raise IOError("The image could not be opened or is empty.")

    frames = panorama_to_stereo_multiprojections(pano_array, stereographic_image_size, FOV)
    frames_detections_with_meta = []
    for frame in frames:
        detections = detect(frame['image'], confidence_threshold=0.45)
        cleaned_detections = []
        for detection in detections:
            box = detection['box']
            if not (box[0] < 5 or box[1] < 5 or box[0] + box[2] > frame['image'].shape[0] - 5 or box[1] + box[3] > frame['image'].shape[1] - 5):
                cleaned_detections.append(detection)
        detections_with_meta = (cleaned_detections, frame['yaw'], frame['pitch'])
        frames_detections_with_meta.append(detections_with_meta)

    frames_detections_with_meta_np = np.array(frames_detections_with_meta, dtype=np.dtype([('image_detections', np.ndarray), ('yaw', int), ('pitch', int)]))
    output_panorama_np, panorama_detections = stereo_bounding_boxes_to_panorama(frames_detections_with_meta_np, pano_array, stereographic_image_size, FOV)

    json_pano_detections = []
    for detection_index in range(panorama_detections.shape[0]):
        json_pano_detections.append(panorama_detections[detection_index][0])
    if output_json_file_path:
        json_object = json.dumps(json_pano_detections, indent=4)
        with open(output_json_file_path, "w") as outfile:
            outfile.write(json_object)
    if output_image_file_path:
        cv2.imwrite(output_image_file_path, output_panorama_np)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", default="model-runs\\detect\\train\\weights\\yolov8n.onnx", help="Input your ONNX model.")
    parser.add_argument("--video", help="Path to input 360 video.")
    parser.add_argument("--img", help="Path to input 360 image.")
    parser.add_argument("--stereo_image_size", help="The size in pixels of the stereographic images derived from the panorama", default="640x640")
    parser.add_argument("--FOV", help="", default="180x180")
    parser.add_argument("--output_detections", help="Path to output json file for the detections.", default=None)
    parser.add_argument("--output_frames", help="Path to output frame(s).", default=None)
    parser.add_argument("--threads", type=int, help="Number of threads for parallelization (video only)", default=1)
    parser.add_argument("--seconds_process", type=int, help="Number of seconds in the video (from the start) to process", default=-1)
    args = parser.parse_args()

    try:
        width, height = map(int, args.stereo_image_size.split('x'))
        stereographic_image_size = (width, height)
    except ValueError:
        raise argparse.ArgumentTypeError("Size must be WxH, where W and H are integers.")
    try:
        theta, phi = map(int, args.FOV.split('x'))
        FOV = (theta, phi)
    except ValueError:
        raise argparse.ArgumentTypeError("FOV Angles must be ThetaxPhi, where Theta and Phi are integers. See stereo.py description for specifics on angles.")

    output_image_file_path = args.output_frames
    output_json_file_path = args.output_detections
    thread_count = args.threads
    seconds_process = args.seconds_process

    if thread_count < 1:
        raise argparse.ArgumentTypeError("thread_count must be an integer greater than zero.")

    if args.video:
        input_video_path = args.video
        video_detection(input_video_path, stereographic_image_size, FOV, output_image_file_path, output_json_file_path, thread_count, seconds_process)
    elif args.img:
        input_panorama_path = args.img
        image_detection(input_panorama_path, stereographic_image_size, FOV, output_image_file_path, output_json_file_path)

if __name__ == '__main__':
    main()
